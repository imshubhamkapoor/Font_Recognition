# Font_Recognition

## Introduction to Project

In this project, you'll train a convolutional neural network to classify and recognize different categories of fonts. We'll be using the dataset of 100 categories of fonts to train our model.
The project is broken down into multiple steps:
- Generating the dataset of fonts from package
- Loading and preprocessing the image dataset
- Visualization of samples from the dataset
- Train the Convolutional Neural Network on your dataset
- Use the trained model to predict new fonts

The whole project is implemented in tensorflow.

## Dataset Description

Adobe VFR dataset is the first large-scale, fine-grained benchmark of font text images, for the task of font recognition and retrieval. Unfortunately, it is very huge so I was unable to download it. Then, I discovered the [TRDG](https://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html) (Text Recognition Data Generator) package created by Edouard Belval in Python. It is a synthetic data generator for text recognition.

### How does the Belval's original TRDG package work?

Words will be randomly chosen from a dictionary of a specific language. Then, an image of those words will be generated by using font, background, and modifications (skewing, blurring, etc.) as specified.
The usage as a Python module is very similar to the CLI.

But the problem arose when I had to create a dataset in a systematic manner with particular font images in their respective folders. As you can see that the original TRDG package produces random images in a single folder from the total list of fonts unless specified a particular font and directory. According to which, I have to run the package for each font and its directory again and again.

### How does my TRDG package work?

I modified the above package to suit my problem. I created a loop inside the main file (run.py) to create a directory for each font provided in the font list (folder) and store its images respectively. Now, after running the package once, it generates font images and stores them in their specified folder (named after that particular font) in a loop for each font provided in the font list. 

I have kept my package in the [trdg](https://github.com/imshubhamkapoor/Font_Recognition/tree/master/trdg) folder to run it separately from the main pipeline. All the rest of the documentation and working is the same as per Belval's original package.

### How I created my dataset?

I ran the package several times in CLI setting different parameters every time to create some distortion in the dataset:
- Run the main file to produce basic images consisting of 70% of the dataset. 

`python run.py -c <no. of images>`

- Run the main file to produce sine-wave distortion consisting of 10% of the dataset. Argument -d has 3 possible values:
0. None
1. Sine wave
2. Cosine wave
3. Random

`python run.py -c <no. of images> -d <1>`

- Run the main file to produce random wave distortion consisting of 10% of the dataset. 

`python run.py -c <no. of images> -d <3>`

- Run the main file to produce skewed fonts images consisting of 5% of the dataset. Argument -k is the skew angle and -rk is set to True to enable random skewing between the range of positive and negative k

`python run.py -c <no. of images> -k <skew angle> -rk <True>`

- Run the main file to apply the gaussian blur to the resulting sample consisting of 5% of the dataset. Argument -bl is an integer defining the blur radius and -rbl is set to True to enable random blur between the range of positive and negative bl.

`python run.py -c <no. of images> -bl <blur radius> -rbl <True>`

**NOTE:** All the resulting images are pre-processed by cropping them to 100x100 pixels. The input dataset must be of fixed dimensions before passing them into the model for training.

## Files Description

- **trdg** The (Text Recognition Data Generator) [TRDG](https://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html) package created by Edouard Belval in Python. It is a synthetic data generator for text recognition.
- **train** It contains the training dataset of 100 types of fonts consisting of 1000 sample images per font (100x100 pixels RGB) provided in a jpeg format.
- **valid** It contains the validation dataset of 100 types of fonts consisting of 200 sample images per font (100x100 pixels RGB) provided in a jpeg format.
- **test** It contains the test dataset. Any test image can be put here for prediction.
- **train.py** It contains the code for loading and pre-processing the dataset. It is also used in training the model using tensorflow and saving it for further use.
- **test.py** It contains the code for loading and pre-processing the image for testing. The pre-trained model in train.py is loaded for making the prediction.
- **utils.py** It contains the functions, models along with any supporting code, which is imported by main files for implementation - train.py and test.py

## Installation
The Code is written in Jupyter Notebook.

Additional Packages that are required are: Numpy, Pandas, MatplotLib, Pytorch, and PIL. You can donwload them using pip

`pip install numpy pandas matplotlib pil`

In order to intall Pytorch head over to the [Pytorch](https://pytorch.org/get-started/locally/) website and follow the instructions given.

## GPU/CPU

As this project uses deep CNNs, for training of network you need to use a GPU. However after training you can always use normal CPU for the prediction phase.

## License
[MIT License](https://github.com/imshubhamkapoor/Kuzushiji_MNIST_Japanese_Character_Classification/blob/master/LICENSE)

## Author
Shubham Kapoor
